{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"../assets/plot_styles.mplstyle\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import redis\n",
    "\n",
    "sys.path.append('../library')\n",
    "from core import flattenWithGenerator, createSlidingWindows\n",
    "from midStats import linearModelGeneral\n",
    "from plotting import loadPalette, loadTableStyles\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Ellipse\n",
    "from adjustText import adjust_text\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "colorPalette = loadPalette()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Script Flow\n",
    "- Look at the composition of weekly top tens as a function of time\n",
    "- Examine points where this trend changed\n",
    "- Look at the RBR of different movies as a function of some of their other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- Using data from tmdb and then two other sources of box office data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDf = pd.read_csv(os.path.join('../data/', 'tmdbDetails.csv'))\n",
    "tmdbDf.drop_duplicates(subset='imdb_id', inplace=True, keep='last')\n",
    "tmdbDict = tmdbDf.set_index('imdb_id').to_dict('index')\n",
    "\n",
    "bomDf = pd.read_csv(os.path.join('../data/', 'allBoxOffice.csv'))\n",
    "bomDf.drop_duplicates(subset=['imdbId','dayNumber'], inplace=True, keep = 'last')\n",
    "bomDf.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "tnDf = pd.read_csv(os.path.join('../data/', 'numbersBoxOffice.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveImagePath = '../assets/savedImages/whatHappenedToTheComedy'\n",
    "\n",
    "if not os.path.exists(saveImagePath):\n",
    "    os.makedirs(saveImagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDf.rename(columns={'imdb_id':'imdbId'}, inplace=True)\n",
    "tmdbWithBoxOfficeDf = tmdbDf[tmdbDf['imdbId'].isin(tnDf['imdbId'].unique())]\n",
    "tmdbWithBoxOfficeDf = tmdbWithBoxOfficeDf[['budget','imdbId','revenue','genres']]\n",
    "tmdbWithBoxOfficeDf.drop_duplicates(subset='imdbId', keep='last', inplace=True)\n",
    "tmdbWithBoxOfficeDf.set_index('imdbId',inplace=True, drop=True)\n",
    "tmdbBODict = tmdbWithBoxOfficeDf.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnDf['tmdbData'] = tnDf['imdbId'].map(tmdbBODict)\n",
    "tnDf[['budget','revenue','genres']] = pd.json_normalize(tnDf['tmdbData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractGenres(g):\n",
    "    gList = ast.literal_eval(g)\n",
    "    genOut = [e['name'] for e in gList]\n",
    "    return genOut\n",
    "\n",
    "tnDf['genresExtracted'] = tnDf['genres'].apply(lambda x: extractGenres(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate weekly rankings -- loaded ranks don't seem to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnDf.sort_values(by=['dateDt', 'weekGross'], ascending=[False, False], inplace=True)\n",
    "\n",
    "tnDf['rank'] = tnDf.groupby('dateDt').cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get percentage of total weekly box office each genre accounts for\n",
    "- This is more robust than just top ten\n",
    "- We're doing some mapping here of the more obscure genres to more standardized ones. This could have an impact on results, but is a useful step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omitGenres = []\n",
    "\n",
    "genreMap = {\n",
    "    'Action/Thriller': ['Action','Western','War', 'Adventure'],\n",
    "    'Suspense':['Thriller','Crime','Mystery'],\n",
    "    'Romance': ['Romance'],\n",
    "    'Animated/Family': ['Animation','Family'],\n",
    "    'Sci-Fi/Fantasy': ['Science Fiction','Fantasy'],\n",
    "    'Comedy': ['Comedy'],\n",
    "    'Drama': ['Drama'],\n",
    "    'Documentary':['Documentary'],\n",
    "    'Misc':['TV Movie','Music','History','']\n",
    "}\n",
    "\n",
    "allGenres = list(genreMap.keys())\n",
    "\n",
    "def calculateRatios(row: pd.Series):\n",
    "    lst = row['genresExtracted']\n",
    "    weekGross = row['weekGross']\n",
    "    lstMapped = list(flattenWithGenerator([[k for k,v in genreMap.items() if el in v] for el in lst]))\n",
    "\n",
    "    total_count = len(lstMapped)\n",
    "    counter = Counter(lstMapped)\n",
    "\n",
    "    proportions = {key: (value / total_count)*weekGross for key, value in counter.items()}\n",
    "\n",
    "    for key in genreMap.keys():\n",
    "        if key not in proportions.keys():\n",
    "            proportions[key] = 0\n",
    "\n",
    "    return proportions\n",
    "\n",
    "tnDf['proportions'] = tnDf.apply(lambda row: calculateRatios(row), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportions of weekly totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeklyTotals = tnDf.groupby('dateDt')['weekGross'].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOverallContribution(group):\n",
    "    allDicts = group['proportions']\n",
    "    totalGross = group['weekGross'].sum()\n",
    "\n",
    "    overallContributions = {}\n",
    "    for k in genreMap.keys():\n",
    "        kSum = 0\n",
    "        for d in allDicts:\n",
    "            kSum += d[k]\n",
    "        \n",
    "        if ratio:\n",
    "            overallContributions[k] = kSum/totalGross\n",
    "        else:\n",
    "            overallContributions[k] = kSum\n",
    "\n",
    "    return overallContributions\n",
    "\n",
    "overallContributions = tnDf.groupby('dateDt').apply(lambda group: calculateOverallContribution(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conDict = overallContributions.to_dict()\n",
    "conDf = pd.DataFrame.from_dict(conDict).T\n",
    "conDf.reset_index(drop=False, inplace=True)\n",
    "conDf['index'] = pd.to_datetime(conDf['index'])\n",
    "conDf.set_index('index', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDf = conDf[conDf.index > pd.to_datetime('1900-01-01', utc=True )]\n",
    "\n",
    "yearRoll = 5*52\n",
    "\n",
    "rollingDf = plotDf.rolling(window=(yearRoll)).mean()\n",
    "normRollingDf = rollingDf.div(rollingDf.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# Create the stack plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plotting the stack plot\n",
    "ax.stackplot(normRollingDf.index, normRollingDf.T, labels=normRollingDf.columns)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_title(f'{int(yearRoll/52)} Year Rolling Average')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Box Office Proportion')\n",
    "# Reverse the order of the legend labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='upper left')\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'distributionsOverTime.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn above image into an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation = input(\"Are you sure you want to proceed (This takes a longggg time)? (yes/no): \")\n",
    "\n",
    "if confirmation.lower() == 'yes':\n",
    "    plotDf = conDf[conDf.index > pd.to_datetime('1900-01-01', utc=True)]\n",
    "\n",
    "    rollingDf = plotDf.rolling(window=(yearRoll)).mean()\n",
    "    rollingDf.dropna(how='all', axis=0, inplace=True)\n",
    "    normRollingDf = rollingDf.div(rollingDf.sum(axis=1), axis=0)\n",
    "\n",
    "    # Create the stack plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "    def update(i):\n",
    "        ax.clear()\n",
    "        plotDf = normRollingDf.iloc[0:i+1]\n",
    "        ax.stackplot(plotDf.index, plotDf.T, labels=plotDf.columns)\n",
    "\n",
    "        ax.set_title(f'{int(yearRoll / 52)} Year Rolling Average')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Box Office Proportion')\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles[::-1], labels[::-1], loc='upper left')\n",
    "\n",
    "    fps = 50\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=range(len(normRollingDf)))\n",
    "\n",
    "    # Save the animation to an mp4 file\n",
    "    ani.save(os.path.join(saveImagePath, 'genreDistributions.mp4'), writer='ffmpeg', fps=fps, dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conDf.dropna(how = 'all', inplace=True)\n",
    "\n",
    "rollingDf = conDf.rolling(window=(yearRoll)).mean()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "for c in rollingDf.columns:\n",
    "    if c in ['Romance','Comedy','Suspense','Sci-Fi/Fantasy','Action/Thriller']:\n",
    "        lw=3\n",
    "        opacity = 1\n",
    "    else:\n",
    "        lw=.5\n",
    "        opacity = .5\n",
    "\n",
    "    ax.plot(rollingDf[c], label=f\"{c}\", lw=lw, alpha = opacity)\n",
    "\n",
    "ax.set_title(f'{int(yearRoll/52)} Year Rolling Average')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Box Office Proportion')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'linePlotsOverTime.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Regressions\n",
    "- Using date as the x variable will tell us if there is a meaningful relationship between time and proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTable = []\n",
    "tests = ['Comedy','Sci-Fi/Fantasy','Action/Thriller', 'Romance', 'Suspense']\n",
    "\n",
    "for test in tests:\n",
    "    y = conDf[test]\n",
    "    X = np.arange(0, len(y))\n",
    "\n",
    "    model = linearModelGeneral(X, y, [1])\n",
    "\n",
    "    outputTable.append(\n",
    "        [test, model['params']['x1'], model['F'], model['p']]\n",
    "    )\n",
    "\n",
    "print(tabulate(outputTable, headers=['Genre', 'x1', 'F', 'p']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflection point analysis\n",
    "- We're now going to look at whether there are corners in the line that are sharper than expected\n",
    "- To do this, we'll essentially be doing some smoothed calculation second derivative stuff... but a bit different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bowtieAnalysis(slopeWindow):\n",
    "    \"\"\"\n",
    "        - On a sliding window, if we calculate the slope differential across an interval of slopes,\n",
    "        we'll essentially find the sharpest X's on a graph\n",
    "\n",
    "    \"\"\"\n",
    "    curveDifferential = slopeWindow[-1] - slopeWindow[0]\n",
    "    \n",
    "    return abs(curveDifferential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))  # Create a 2x2 grid of subplots\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "for idx, test in enumerate(['Comedy', 'Sci-Fi/Fantasy', 'Action/Thriller', 'Suspense']):  # Limit to the first 4 tests for the 2x2 grid\n",
    "    ax = axs[idx // 2, idx % 2]\n",
    "    plotDf = rollingDf.dropna(subset=test)\n",
    "    # plotDf = pd.DataFrame(scaler.fit_transform(rollingDf), columns=rollingDf.columns, index=rollingDf.index)\n",
    "    values = np.array(plotDf[test])\n",
    "\n",
    "    windowSize = 150\n",
    "    overlap = int(windowSize / 1.05)\n",
    "\n",
    "    windows = createSlidingWindows(l=values, windowSize=windowSize, overlap=overlap)\n",
    "\n",
    "    windowPreds = []\n",
    "    slopes = []\n",
    "    for i, window in enumerate(windows):\n",
    "        y = window\n",
    "        X = np.arange(0, len(y))\n",
    "        model = linearModelGeneral(X, y, [1])\n",
    "        slope = model['params'][-1]\n",
    "\n",
    "        coefficients = np.polyfit(X,y,1)\n",
    "        slope = coefficients[0]\n",
    "\n",
    "        overallIndices = [((windowSize * i) - (overlap * i)) + j for j, k in enumerate(X)]\n",
    "        preds = model['ypred']\n",
    "\n",
    "        windowPreds.append(list(zip(overallIndices, preds))) # This is for plotting\n",
    "        slopes.append(slope) # This is for determining most turbulant windows\n",
    "\n",
    "    # Find max standard deviation across three slopes\n",
    "    slopeWindowSize = 10\n",
    "    slopeStep = slopeWindowSize - 1\n",
    "    slopeWindows = createSlidingWindows(l=slopes, windowSize = slopeWindowSize, overlap = slopeStep) # the reason that we're sliding here is because we want to consider all possible windows\n",
    "\n",
    "    windowStds = [bowtieAnalysis(window) for window in slopeWindows]\n",
    "\n",
    "    maxIdxs = np.argsort([s for s in windowStds if s == s])[::-1]\n",
    "\n",
    "    maxIdxsFiltered = []\n",
    "    for j,i in enumerate(maxIdxs):\n",
    "        if j==0:\n",
    "            maxIdxsFiltered.append(i)\n",
    "        else:\n",
    "            if any(np.abs(np.array(maxIdxsFiltered) - i) < slopeWindowSize*3):\n",
    "                continue\n",
    "\n",
    "            if len(maxIdxsFiltered) >= 3:\n",
    "                break\n",
    "\n",
    "            maxIdxsFiltered.append(i)\n",
    "\n",
    "    maxIdxsFull = []\n",
    "    for idx in maxIdxsFiltered:\n",
    "        startIdx = (idx * slopeWindowSize) - (slopeStep * idx)\n",
    "        newIdxs = [i for i in range(startIdx, startIdx + slopeWindowSize)]\n",
    "        maxIdxsFull += newIdxs\n",
    "\n",
    "\n",
    "    ax.plot(np.arange(len(plotDf)), values, c='k', alpha=1, zorder=2)\n",
    "    \n",
    "    for i, pred in enumerate(windowPreds):\n",
    "        Xplot, yplot = zip(*pred)\n",
    "        \n",
    "        color = ('cherry',.75,2) if i in maxIdxsFull else ('blue_grey_dark',.5,1)\n",
    "        ax.plot(Xplot, yplot, c=loadPalette()[color[0]], alpha=color[1], lw=4, zorder=color[2])\n",
    "\n",
    "    # Convert index to datetime and extract year\n",
    "    plotDf.index = pd.to_datetime(plotDf.index)\n",
    "    custom_ticks = np.arange(0, len(plotDf), step=256)\n",
    "    custom_labels = plotDf.index[::256].year\n",
    "\n",
    "    # Set custom ticks and labels\n",
    "    ax.set_xticks(custom_ticks)\n",
    "    ax.set_xticklabels(custom_labels)\n",
    "\n",
    "    ax.set_title(f'{test} - Rolling Window Predictions')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Box Office Proportion Normed')\n",
    "\n",
    "# fig.subplots_adjust(hspace=0.35, wspace=0.15)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, hspace=0.35, wspace=0.15)\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'windowedAverages.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studio prevalence\n",
    "- Essentially repeating genre analysis, but substituting studio for genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodDf = tmdbDf.copy(deep=True)\n",
    "\n",
    "prodDf = prodDf[prodDf['production_companies'] != '[]']\n",
    "\n",
    "def getCompanies(s):\n",
    "    j = ast.literal_eval(s)\n",
    "    return [e['name'] for e in j]\n",
    "\n",
    "prodDf['productionCompanies'] = prodDf['production_companies'].apply(lambda x: getCompanies(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyDict = prodDf.set_index('imdbId')['productionCompanies'].to_dict()\n",
    "companyDict = {k:v for k,v in companyDict.items() if v!=['Private']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnDf['productionCompany'] = tnDf['imdbId'].map(companyDict)\n",
    "expDf = tnDf.explode('productionCompany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distDf = pd.DataFrame(expDf.groupby(['dateDt','productionCompany'])['weekGross'].sum()).reset_index(drop=False)\n",
    "distDf['proportions'] = distDf.groupby('dateDt')['weekGross'].transform(lambda g: g / g.sum())\n",
    "\n",
    "distDf = distDf[['dateDt','productionCompany','proportions']]\n",
    "\n",
    "pivotDf = distDf.pivot(index='dateDt', columns='productionCompany', values='proportions')\n",
    "pivotDf.fillna(0, inplace=True)\n",
    "\n",
    "# Only keep columns where there is a min value of .1\n",
    "\n",
    "yearRoll = 2*52\n",
    "\n",
    "rollingDf = pivotDf.rolling(window=(yearRoll)).mean()\n",
    "rollingDf = rollingDf.loc[:, (rollingDf >= .04).any()]\n",
    "print(f\"NUMBER OF STUDIOS AFTER FILTER: {len(rollingDf.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stack plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "normRollingDf = rollingDf.div(rollingDf.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# Plotting the stack plot\n",
    "ax.stackplot(normRollingDf.index, normRollingDf.T, labels=normRollingDf.columns)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_title(f'Box Office by Studio') \n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Box Office Proportion')\n",
    "# Reverse the order of the legend labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='upper left')\n",
    "\n",
    "# Select 8 evenly spaced ticks\n",
    "num_ticks = 8\n",
    "tick_positions = np.linspace(0, len(normRollingDf.index) - 1, num_ticks, dtype=int)\n",
    "custom_ticks = normRollingDf.index[tick_positions]\n",
    "\n",
    "# Format the ticks to display only the year\n",
    "custom_labels = [pd.to_datetime(tick).year for tick in custom_ticks]\n",
    "\n",
    "# Set custom ticks and labels\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(custom_labels)\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'studioDistributions.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination of the early 90s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minDate1 = pd.to_datetime('1987-01-01', utc=True)\n",
    "maxDate1 = pd.to_datetime('1990-01-01', utc=True)\n",
    "minDate2 = pd.to_datetime('1990-01-01', utc=True)\n",
    "maxDate2 = pd.to_datetime('1993-01-01', utc=True)\n",
    "\n",
    "dateRanges = [(minDate1, maxDate1), (minDate2, maxDate2)]\n",
    "\n",
    "for minDate,maxDate in dateRanges:\n",
    "    tmdbDf['release_date'] = pd.to_datetime(tmdbDf['release_date'], utc=True)\n",
    "\n",
    "    df1992 = tmdbDf[((tmdbDf['release_date'] >= minDate) & (tmdbDf['release_date'] < maxDate))]\n",
    "\n",
    "    df1992.drop_duplicates(subset='imdbId', inplace=True, keep='last')\n",
    "\n",
    "    df1992.sort_values(by='revenue', inplace=True, ascending = False)\n",
    "    df1992['genresExtracted'] = df1992['genres'].apply(lambda x: extractGenres(x))\n",
    "\n",
    "    dfDisplay = df1992[['title', 'revenue', 'release_date', 'genresExtracted']].head(10)\n",
    "    dfDisplay.columns = ['Title','Lifetime Revenue', 'Release Date', 'Genres']\n",
    "    dfDisplay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Define formatting function\n",
    "    def formatMillions(x):\n",
    "        return f\"${x / 1_000_000:.2f}M\"\n",
    "    \n",
    "    def formatRelease(x):\n",
    "        return f\"{x.year}-{x.month}-{x.day}\"\n",
    "\n",
    "    # Apply formatting to 'Lifetime Revenue' column\n",
    "    dfDisplay['Lifetime Revenue'] = dfDisplay['Lifetime Revenue'].apply(formatMillions)\n",
    "    dfDisplay['Release Date'] = dfDisplay['Release Date'].apply(formatRelease)\n",
    "\n",
    "    styled_df = dfDisplay.style.set_table_styles(loadTableStyles())\n",
    "    display(Markdown(f\"<h3 style='font-family:monospace; background-color:{loadPalette()['canvas_dark']}; color:black; padding:10px; margin-bottom:0;'>Movies Released Between {minDate.date()} and {maxDate.date()}</h3>\"))\n",
    "    display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination of comedy RBRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDf.dropna(subset='genres', inplace=True)\n",
    "comedyDf = tmdbDf[tmdbDf['genres'].str.contains('Comedy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedyDf['RBR'] = comedyDf['revenue'] / comedyDf['budget']\n",
    "comedyDf = comedyDf[comedyDf['revenue']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formatter function\n",
    "def millions(x, pos):\n",
    "    return f'{x * 1e-6:.1f}M'\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(comedyDf['budget'], comedyDf['revenue'], c = loadPalette()['blue_grey_dark'])\n",
    "\n",
    "# Define line points\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Slope of one\n",
    "\n",
    "# Plot line\n",
    "ax.plot(x_vals, y_vals, '--', color=loadPalette()['cherry'], label='Revenue == Budget')\n",
    "\n",
    "# Apply formatter to x and y axes\n",
    "formatter = FuncFormatter(millions)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('Budget')\n",
    "ax.set_ylabel('Revenue')\n",
    "\n",
    "# Annotate outliers\n",
    "texts = []\n",
    "for i, row in comedyDf.iterrows():\n",
    "    if row['RBR'] > 5 and row['budget'] >= 100_000_000:\n",
    "        texts.append(ax.text(\n",
    "            row['budget'], row['revenue'], row['title'],\n",
    "            fontsize=8, fontfamily='monospace', alpha=0.75\n",
    "        ))\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.25))\n",
    "        \n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'xyScatterAll.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midBudgetDf = comedyDf[((comedyDf['budget']<75_000_000) & (comedyDf['budget'] > 19_000_000))]\n",
    "midBudgetDf = midBudgetDf[midBudgetDf['genres'].str.contains('Animation') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming midBudgetDf and loadPalette() are already defined\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "\n",
    "# Replace infinite values with NaN and drop rows with NaN in 'RBR'\n",
    "midBudgetDf.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "midBudgetDf.dropna(subset=['RBR'], inplace=True)\n",
    "\n",
    "# Calculate Q1, Q3, and IQR\n",
    "Q1 = midBudgetDf['RBR'].quantile(0.15)\n",
    "Q3 = midBudgetDf['RBR'].quantile(0.85)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outliers\n",
    "outliers = midBudgetDf[(midBudgetDf['RBR'] < Q1 - 1.5 * IQR) | (midBudgetDf['RBR'] > Q3 + 1.5 * IQR)]\n",
    "outliers.drop_duplicates(subset='imdbId', keep='last', inplace=True)\n",
    "# Plot regular points\n",
    "ax.scatter(midBudgetDf['budget'], midBudgetDf['revenue'], c=loadPalette()['blue_grey_dark'], zorder=1)\n",
    "\n",
    "# Plot outliers\n",
    "ax.scatter(outliers['budget'], outliers['revenue'], c=loadPalette()['cherry'], s=10, zorder=2)\n",
    "\n",
    "# Apply formatter to x and y axes\n",
    "formatter = FuncFormatter(millions)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('Budget')\n",
    "ax.set_ylabel('Revenue')\n",
    "\n",
    "# Annotate outliers\n",
    "texts = []\n",
    "for i, row in outliers.iterrows():\n",
    "    texts.append(ax.text(\n",
    "        row['budget'], row['revenue'], row['title'],\n",
    "        fontsize=8, fontfamily='monospace', alpha=0.75\n",
    "    ))\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.25))\n",
    "\n",
    "# Define line points\n",
    "ax.set_xlim(19_000_000, 75_000_000)\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Slope of one\n",
    "\n",
    "# Plot line\n",
    "ax.plot(x_vals, y_vals, '--', color=loadPalette()['cherry'], label='Revenue == Budget')\n",
    "plt.legend()\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'xyScatterOutliers.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cast list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMDB_API_KEY = os.getenv(\"TMDB_API_KEY\")\n",
    "TMDB_AUTH_TOKEN = os.getenv(\"TMDB_AUTH_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCast(imdbId, justNames: bool = True):\n",
    "    \n",
    "    url = f\"https://api.themoviedb.org/3/movie/{imdbId}/credits?language=en-US\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TMDB_AUTH_TOKEN}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    rJ = json.loads(response.text)['cast']\n",
    "\n",
    "    if justNames:\n",
    "\n",
    "        names = [person['name'] for person in rJ if person['known_for_department'] == 'Acting'][:5]\n",
    "        \n",
    "        return ', '.join(names)\n",
    "\n",
    "    else:\n",
    "        return rJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midBudgetDf.drop_duplicates(subset='imdbId', keep='last',inplace=True)\n",
    "goodDfDisplay = midBudgetDf[['title','revenue','budget','RBR', 'imdbId']].sort_values(by='RBR', ascending = False).head(20)\n",
    "goodDfDisplay['cast'] = goodDfDisplay['imdbId'].apply(lambda x: getCast(x))\n",
    "goodDfDisplay.drop(columns=['imdbId'], inplace=True)\n",
    "goodDfDisplay.columns = ['Title','Lifetime Revenue','Budget', 'RBR', 'Cast']\n",
    "goodDfDisplay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Apply formatting to 'Lifetime Revenue' column\n",
    "goodDfDisplay['Lifetime Revenue'] = goodDfDisplay['Lifetime Revenue'].apply(formatMillions)\n",
    "goodDfDisplay['Budget'] = goodDfDisplay['Budget'].apply(formatMillions)\n",
    "goodDfDisplay['RBR'] = goodDfDisplay['RBR'].round(2)\n",
    "\n",
    "styledDf = goodDfDisplay.style.set_table_styles(loadTableStyles()).format({'RBR': '{:.2f}'})\n",
    "display(Markdown(f\"<h3 style='font-family:monospace; background-color:{loadPalette()['canvas_dark']}; color:black; padding:10px; margin-bottom:0;'>Highest comedy RBRs</h3>\"))\n",
    "display(styledDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midBudgetDf.drop_duplicates(subset='imdbId', keep='last',inplace=True)\n",
    "badDfDisplay = midBudgetDf[['title','revenue','budget','RBR', 'imdbId']].sort_values(by='RBR', ascending = True).head(20)\n",
    "badDfDisplay['cast'] = badDfDisplay['imdbId'].apply(lambda x: getCast(x))\n",
    "badDfDisplay.drop(columns=['imdbId'], inplace=True)\n",
    "badDfDisplay.columns = ['Title','Lifetime Revenue','Budget', 'RBR', 'Cast']\n",
    "badDfDisplay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Apply formatting to 'Lifetime Revenue' column\n",
    "badDfDisplay['Lifetime Revenue'] = badDfDisplay['Lifetime Revenue'].apply(formatMillions)\n",
    "badDfDisplay['Budget'] = badDfDisplay['Budget'].apply(formatMillions)\n",
    "badDfDisplay['RBR'] = badDfDisplay['RBR'].round(4)\n",
    "\n",
    "styledDf = badDfDisplay.style.set_table_styles(loadTableStyles()).format({'RBR': '{:.4f}'})\n",
    "display(Markdown(f\"<h3 style='font-family:monospace; background-color:{loadPalette()['canvas_dark']}; color:black; padding:10px; margin-bottom:0;'>Lowest comedy RBRs</h3>\"))\n",
    "display(styledDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dfs with Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodDf = midBudgetDf.sort_values(by='RBR', ascending = False).head(50)\n",
    "badDf = midBudgetDf.sort_values(by='RBR', ascending = True).head(50)\n",
    "\n",
    "goodDf['classification'] = 'good'\n",
    "badDf['classification'] = 'bad'\n",
    "\n",
    "mergedDf = pd.concat([goodDf, badDf])\n",
    "mergedDict = mergedDf.to_dict('records')\n",
    "castDict = list(mergedDf['imdbId'].apply(lambda x: getCast(x, False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the star power\n",
    "- We're going to loop through all of the cast members of the movies and we are going to get:\n",
    "    - Their age at the time of movie release\n",
    "    - The success of the last x of their movies\n",
    "    - Their billing success...\n",
    "\n",
    "        - We could potentially run something that is a bit more robust here... but that's a story for a differnet day\n",
    "            - Essentially create a simple ml algorithm, and determine shapley vals for each person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're doing some really janky API calls here. \n",
    "- To get cast details on every movie, we'll set this up as an asyncio function, but since it's only 100, I'll just take the dog for a walk while it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalStarPower = {}\n",
    "confirmation = input(\"Are you sure you want to proceed (This takes a longggg time)? (yes/no): \")\n",
    "\n",
    "if confirmation.lower() == 'yes':\n",
    "\n",
    "    for i, movie in tqdm(enumerate(castDict), total=len(castDict)):\n",
    "        curMovie = mergedDict[i]\n",
    "        curMovieRelease = curMovie['release_date']\n",
    "\n",
    "        movieTotalAttributions = 0\n",
    "\n",
    "        # Only going to keep the top 10 billings\n",
    "        for k, person in enumerate(movie[:5], start=1):\n",
    "            personId = person['id']\n",
    "\n",
    "            url0 = f\"https://api.themoviedb.org/3/person/{personId}?language=en-US\"\n",
    "            url1 = f\"https://api.themoviedb.org/3/person/{personId}/combined_credits?language=en-US\"\n",
    "            personDetails = requests.get(url0, headers=headers).json()\n",
    "            creditDetails = requests.get(url1, headers=headers).json()['cast']\n",
    "\n",
    "            previousAttributions = 0\n",
    "\n",
    "            # Loop through cast members' past credits\n",
    "            for credit in creditDetails:\n",
    "                creditId = credit['id']\n",
    "\n",
    "                imdbUrl = f\"https://api.themoviedb.org/3/movie/{creditId}/external_ids\"\n",
    "\n",
    "                imdbDetails = requests.get(imdbUrl,headers=headers)\n",
    "\n",
    "                if imdbDetails.status_code != 200:\n",
    "                    continue\n",
    "\n",
    "                imdbId = imdbDetails.json()['imdb_id']\n",
    "                \n",
    "                if imdbId == None or imdbId == ''  or imdbId not in tmdbDict.keys():\n",
    "                    continue\n",
    "\n",
    "                movieDetails = tmdbDict[imdbId]\n",
    "\n",
    "                if movieDetails['revenue'] == 0 or movieDetails['revenue'] != movieDetails['revenue']:\n",
    "                    continue\n",
    "                if movieDetails['budget'] == 0 or movieDetails['budget'] != movieDetails['budget']:\n",
    "                    continue\n",
    "\n",
    "                releaseDelta = (curMovieRelease - pd.to_datetime(movieDetails['release_date'], utc=True)).days\n",
    "\n",
    "                if releaseDelta <= 0:\n",
    "                    continue\n",
    "            \n",
    "                #okay... so we now have only movies release before the release date... let's calculate the RBR as a function of billing\n",
    "                RBR = movieDetails['revenue'] / movieDetails['budget']\n",
    "\n",
    "                movieCast = getCast(imdbId, False)\n",
    "\n",
    "                billing = [j for j,e in enumerate(movieCast, start=1) if e['id'] == personId]\n",
    "\n",
    "                if len(billing) == 0:\n",
    "                    continue \n",
    "                \n",
    "                # attribution\n",
    "                attribution = (RBR / billing[0]) / k # weighting this based on the current cast list\n",
    "\n",
    "                # Finally, weight the attribution based on how long ago the movie occurred\n",
    "                attributionWeighted = attribution / (releaseDelta / 10)\n",
    "\n",
    "                previousAttributions += attribution\n",
    "\n",
    "            movieTotalAttributions += previousAttributions\n",
    "\n",
    "        totalStarPower[curMovie['imdbId']] = movieTotalAttributions\n",
    "    with open('../data/starPower.json', 'w') as f:\n",
    "        json.dump(totalStarPower, f)\n",
    "else:\n",
    "\n",
    "    print('Phew, let\\'s continue')\n",
    "    with open('../data/starPower.json') as f:\n",
    "        totalStarPower = json.load(f)\n",
    "\n",
    "mergedDf['starPower'] = mergedDf['imdbId'].map(totalStarPower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mean age of stars at time of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageDict = {}\n",
    "\n",
    "for i, movie in tqdm(enumerate(castDict), total=len(castDict)):\n",
    "    curMovie = mergedDict[i]\n",
    "    curMovieRelease = curMovie['release_date']\n",
    "\n",
    "    ages = []\n",
    "\n",
    "    # Only going to keep the top n billings\n",
    "    for k, person in enumerate(movie[:5], start=1):\n",
    "        personId = person['id']\n",
    "\n",
    "        url0 = f\"https://api.themoviedb.org/3/person/{personId}?language=en-US\"\n",
    "        details = requests.get(url0,headers=headers)\n",
    "\n",
    "        if details.status_code != 200:\n",
    "            continue\n",
    "\n",
    "        birthday = pd.to_datetime(details.json()['birthday'], utc=True)\n",
    "\n",
    "        age = relativedelta(curMovieRelease, birthday).years\n",
    "\n",
    "        ages.append(age)\n",
    "\n",
    "    \n",
    "    ageDict[curMovie['imdbId']] = np.mean(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf['starAges'] = mergedDf['imdbId'].map(ageDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve ratings from redis\n",
    "- I have a separate redis db that has a mapping of imdb to imdb rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5 = redis.Redis(\n",
    "    host='127.0.0.1',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    db=5\n",
    ")\n",
    "\n",
    "redisKeys = r5.keys('*')\n",
    "redisValues = [float(i) for i in r5.mget(redisKeys)]\n",
    "\n",
    "redisDict = dict(zip(redisKeys,redisValues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf['imdbRating'] = mergedDf['imdbId'].map(redisDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Function to create a boxplot and overlay t-test results\n",
    "def create_boxplot_with_ttest(ax, df, column):\n",
    "    group_a = df[df['classification'] == 'good'][column]\n",
    "    group_b = df[df['classification'] == 'bad'][column]\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(group_a, group_b)\n",
    "    \n",
    "    # Create boxplot\n",
    "    ax.boxplot([group_a, group_b], labels=['High RBR', 'Low RBR'])\n",
    "    ax.set_title(f'{column}')\n",
    "    ax.set_xlabel('Group')\n",
    "    ax.set_ylabel('Value')\n",
    "    \n",
    "    # Overlay t-test results\n",
    "    ax.text(1.5, max(group_a.max(), group_b.max()), f't-stat: {t_stat:.2f}\\np-value: {p_value:.3f}', \n",
    "            horizontalalignment='center', verticalalignment='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Create a 4x4 grid of plots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8, 8))\n",
    "\n",
    "\n",
    "renameCols = {\n",
    "    'budget':'Budget', \n",
    "    'revenue':'Revenue', \n",
    "    'starAges':'Star Ages',\n",
    "    'starPower':'Star Power',\n",
    "    'runtime':'Runtime', \n",
    "    'imdbRating':'IMDB Rating', \n",
    "}\n",
    "\n",
    "mergedDf.rename(columns=renameCols, inplace=True)\n",
    "\n",
    "for ax, column in zip(axes.flatten(), renameCols.values()):\n",
    "    create_boxplot_with_ttest(ax, mergedDf, column)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'boxplots.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comedies since the hangover with highest RBRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedyDf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentDf = comedyDf[comedyDf['release_date'] >= pd.to_datetime('2010-01-01', utc=True)]\n",
    "recentDf = recentDf[~recentDf['genres'].str.contains('Animation')]\n",
    "recentDf = recentDf[~recentDf['genres'].str.contains('Action')]\n",
    "recentDf = recentDf[~recentDf['genres'].str.contains('Drama')]\n",
    "recentDf = recentDf[recentDf['budget'] > 10_000_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentDf.sort_values(by='RBR', inplace=True, ascending=False)\n",
    "recentDf.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "recentDf.dropna(subset=['RBR'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formatter function\n",
    "fix, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(recentDf['budget'], recentDf['revenue'], c = loadPalette()['blue_grey_dark'])\n",
    "\n",
    "# Define line points\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = x_vals  # Slope of one\n",
    "\n",
    "# Plot line\n",
    "ax.plot(x_vals, y_vals, '--', color=loadPalette()['cherry'], label='Revenue == Budget')\n",
    "\n",
    "# Apply formatter to x and y axes\n",
    "formatter = FuncFormatter(millions)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('Budget')\n",
    "ax.set_ylabel('Revenue')\n",
    "\n",
    "\n",
    "# Calculate Q1, Q3, and IQR\n",
    "Q1 = recentDf['RBR'].quantile(0.25)\n",
    "Q3 = recentDf['RBR'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outliers\n",
    "outliers = recentDf[(recentDf['RBR'] < Q1 - 1.5 * IQR) | (recentDf['RBR'] > Q3 + 1.5 * IQR)]\n",
    "outliers.drop_duplicates(subset='imdbId', keep='last', inplace=True)\n",
    "outliers.sort_values(by='RBR', ascending=False, inplace=True)\n",
    "# Plot outliers\n",
    "ax.scatter(outliers['budget'], outliers['revenue'], c=loadPalette()['cherry'], s=10, zorder=2)\n",
    "\n",
    "# Annotate outliers\n",
    "texts = []\n",
    "for i, row in outliers.iterrows():\n",
    "\n",
    "    if len(texts)>15:\n",
    "        break\n",
    "    texts.append(ax.text(\n",
    "        row['budget'], row['revenue'], row['title'],\n",
    "        fontsize=8, fontfamily='monospace', alpha=0.75\n",
    "    ))\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.25))\n",
    "        \n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'recentOutliers.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
