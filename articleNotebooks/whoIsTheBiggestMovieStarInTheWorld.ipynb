{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"../assets/plot_styles.mplstyle\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import redis\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from bs4 import BeautifulSoup\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "sys.path.append('../library')\n",
    "from core import flattenWithGenerator, createSlidingWindows, exceptionOutput\n",
    "from midStats import linearModelGeneral\n",
    "from plotting import loadPalette, loadTableStyles, createBoxplotWithTTests\n",
    "from imageProcessing import *\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from adjustText import adjust_text\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "\n",
    "colorPalette = loadPalette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveImagePath = '../assets/savedImages/whoIsTheBiggestMovieStarInTheWorld'\n",
    "\n",
    "if not os.path.exists(saveImagePath):\n",
    "    os.makedirs(saveImagePath)\n",
    "\n",
    "TMDB_AUTH_TOKEN = os.getenv('TMDB_AUTH_TOKEN')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TMDB_AUTH_TOKEN}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credits from redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(\n",
    "    host='127.0.0.1',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    db=6\n",
    ")\n",
    "\n",
    "keys = r.keys('*')\n",
    "values = r.mget(keys)\n",
    "\n",
    "creditsDict = []\n",
    "\n",
    "for i,v in enumerate(tqdm(values)):\n",
    "    vJ = json.loads(v)\n",
    "    imdbId = {'imdbId':keys[i]}\n",
    "    cast = [{**c, **imdbId} for c in vJ['cast']]\n",
    "    creditsDict += cast\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditsDf = pd.DataFrame.from_dict(creditsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TMDB Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDfRaw = pd.read_csv('../data/tmdbDetails.csv')\n",
    "tmdbDfRaw.drop_duplicates('imdb_id', keep='last', inplace=True)\n",
    "tmdbDfRaw = tmdbDfRaw[tmdbDfRaw['adult'] == False]\n",
    "tmdbDfRaw = tmdbDfRaw[tmdbDfRaw['genres'].str.contains('Animation') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIds = list(tmdbDfRaw['imdb_id'].unique())\n",
    "\n",
    "with open('../data/allIds.json', 'w') as f:\n",
    "    json.dump(allIds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter TMDB for what we have credits on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(tmdbDf):\n",
    "    \"\"\"\n",
    "    Turning this into a fn as we are going to be repeating these steps on some different versions of the df\n",
    "    It isn't doing anything fancy, just a bunch of pandas business\n",
    "    \"\"\"\n",
    "    tmdbDf = tmdbDf[tmdbDf['imdb_id'].isin(creditsDf['imdbId'].unique())]\n",
    "    tmdbDf.drop_duplicates(subset=['imdb_id'], inplace=True, keep='last')\n",
    "    tmdbDf = tmdbDf[tmdbDf['revenue'] > 0]\n",
    "    tmdbDf = tmdbDf[tmdbDf['budget'] > 0]\n",
    "    tmdbDf = tmdbDf[['imdb_id','release_date','revenue','budget']]\n",
    "    tmdbDf.set_index('imdb_id', inplace=True, drop=True)\n",
    "    tmdbDict = tmdbDf.to_dict('index')\n",
    "\n",
    "    creditsDf['tmdbInfo'] = creditsDf['imdbId'].map(tmdbDict)\n",
    "    expDf = pd.json_normalize(creditsDf['tmdbInfo'])\n",
    "    resDf = creditsDf.drop(columns=['tmdbInfo']).join(expDf)\n",
    "    resDf = resDf[resDf['known_for_department'] == 'Acting']\n",
    "    resDf['contribution'] = resDf['revenue'] / (resDf['cast_id'] + 1) # indexing starts at 0\n",
    "\n",
    "    idNameMap = resDf[['id','name']].set_index('id').to_dict()['name']\n",
    "\n",
    "    totalSums = pd.DataFrame(resDf.groupby('id')[['revenue','contribution']].agg({'sum', 'size'}))\n",
    "    totalSums.columns = ['_'.join(col).strip() for col in totalSums.columns.values]\n",
    "    totalSums.sort_values(by='revenue_sum', ascending=False, inplace=True)\n",
    "    totalSums.drop(columns='contribution_size', inplace=True)\n",
    "    totalSums.rename(columns={'revenue_size':'size'}, inplace=True)\n",
    "    totalSums['name'] = totalSums.index.map(idNameMap)\n",
    "\n",
    "    # get headshots for outliers - going to just select top 50\n",
    "    outliersY1 = totalSums.sort_values(by='revenue_sum', ascending=False).head(50)\n",
    "    outliersY2 = totalSums.sort_values(by='contribution_sum', ascending=False).head(50)\n",
    "\n",
    "    # annotations = [p for p in list(outliersX.index) if p in outliersY.index.unique()]\n",
    "    annotations = [list(outliersY1.index), list(outliersY2.index)]\n",
    "    annotationsFlat = list(flattenWithGenerator(annotations))\n",
    "\n",
    "    cutoff = 20\n",
    "\n",
    "    print(f\"NUMBER OF OUTLIERS = {len (annotationsFlat)}\")\n",
    "    print(f\"ONLY PLOTTING {cutoff}\")\n",
    "\n",
    "    for annotation in tqdm(annotationsFlat[:cutoff]):\n",
    "        getHeadshot(annotation, headers)\n",
    "\n",
    "    for annotation in tqdm(annotationsFlat[:cutoff]):\n",
    "        try:\n",
    "            if len(os.listdir(f'../data/headshots/{annotation}')) == 0:\n",
    "                continue\n",
    "            filePath = f'../data/headshots/{annotation}/{annotation}_0.jpg'\n",
    "            extractFaces(filePath, makePretty=True)\n",
    "        except Exception as e:\n",
    "            print(exceptionOutput(e))\n",
    "            print(annotation)\n",
    "\n",
    "    return totalSums, annotations, annotationsFlat, idNameMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling headshots for people in our outliers\n",
    "- We'll move this to an asyncio when pulling for all actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalSums, annotations, annotationsFlat, idNameMap = preprocessData(tmdbDfRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formatter function\n",
    "def billions(x, pos):\n",
    "    return f'{x * 1e-9:.1f}B'\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize=(8,8))\n",
    "\n",
    "for idx, targetCol in enumerate(['revenue_sum','contribution_sum']):\n",
    "    ax = axs[idx]\n",
    "\n",
    "    ax.scatter(totalSums['size'], totalSums[targetCol], c = loadPalette()['blue_grey_dark'])\n",
    "\n",
    "    # Define line points\n",
    "    x_vals = np.array(ax.get_xlim())\n",
    "    y_vals = x_vals  # Slope of one\n",
    "\n",
    "    # Plot line\n",
    "\n",
    "    # Apply formatter to x and y axes\n",
    "    formatter = FuncFormatter(billions)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.set_xlabel('Number of Credits (non-animated)')\n",
    "\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Cumulative Revenue')\n",
    "    else:\n",
    "        ax.set_ylabel('Adjusted Cumulative Revenue')\n",
    "\n",
    "    xLim = 0\n",
    "    for annotation in annotations[idx][:20]:\n",
    "        try:\n",
    "            imgPath = f'../data/headshots/{annotation}/00_faceExtracted.png'\n",
    "            annotationData = totalSums[totalSums.index == annotation]\n",
    "            \n",
    "            if annotationData['size'].iloc[0] > xLim:\n",
    "                xLim = annotationData['size'].iloc[0]\n",
    "\n",
    "            x, y = annotationData['size'].iloc[0], annotationData[targetCol].iloc[0]\n",
    "            img = Image.open(imgPath)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "            img = img.resize((45, 45), Image.LANCZOS)  # Resize image with high-quality interpolation\n",
    "\n",
    "            imagebox = OffsetImage(img, zoom=0.5)  # Adjust zoom to fit the resized image\n",
    "            ab = AnnotationBbox(imagebox, (x, y), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    ax.set_xlim(0, xLim)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.05, hspace=0.2, wspace=0.15)\n",
    "\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'outlierScatter.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice df showing rankings across three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalSums = totalSums[totalSums['size'] > 20]\n",
    "\n",
    "totalSums['perMovieRevAvg'] = totalSums['revenue_sum'] / totalSums['size']\n",
    "totalSums['perMovieContAvg'] = totalSums['contribution_sum'] / totalSums['size']\n",
    "\n",
    "totalSums.drop(columns='size', inplace=True)\n",
    "\n",
    "\n",
    "rankDict = {}\n",
    "for column in [c for c in totalSums.columns if c != 'name']:\n",
    "    ranks = totalSums[['name',column]].sort_values(by=column, ascending = False)\n",
    "    rankDict[column] = list(ranks['name'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankDf = pd.DataFrame.from_dict(rankDict)\n",
    "rankDf.index.name = 'Rank'\n",
    "rankDf.columns = ['Total Revenue','Total Revenue Adjusted','Avg. Revenue','Avg. Revenue Adjusted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Colors\n",
    "uniqueValues = rankDf.values.ravel('K')\n",
    "counts = Counter(uniqueValues)\n",
    "min3 = [k for k,v in counts.items() if v > 2]\n",
    "colors = list(loadPalette().values())[:len(min3)]\n",
    "color_map = {val: f'background-color: {color}' for val, color in zip(min3, colors)}\n",
    "\n",
    "# Apply colors\n",
    "def highlightCells(val):\n",
    "    return color_map.get(val, '')\n",
    "\n",
    "styledDf = rankDf.style.applymap(highlightCells).set_table_styles(loadTableStyles())\n",
    "display(Markdown(f\"<h3 style='font-family:monospace; background-color:{loadPalette()['canvas_dark']}; color:black; padding:10px; margin-bottom:0;font-weight:bold;'>Revenue Rankings (minimum 20 credits)</h3>\"))\n",
    "display(styledDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out Franchises\n",
    "- Note that the belongs_to_collection column is not perfect (e.g., \"The Eternals\" is missed)\n",
    "- We'll do a secondary filter on production company perhaps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLowestLevelDict(d):\n",
    "    if not isinstance(d, dict):\n",
    "        return [d]\n",
    "    \n",
    "    values = []\n",
    "    for value in d.values():\n",
    "        values.extend(getLowestLevelDict(value))\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/franchiseMappings2.json') as f:\n",
    "    franchiseData = json.load(f)\n",
    "\n",
    "franchiseIds = getLowestLevelDict(franchiseData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = len(tmdbDfRaw)\n",
    "standaloneDf = tmdbDfRaw[tmdbDfRaw['belongs_to_collection'] != tmdbDfRaw['belongs_to_collection']]\n",
    "f2 = len(standaloneDf)\n",
    "standaloneDf = standaloneDf[~standaloneDf['imdb_id'].isin(franchiseIds)]\n",
    "f3 = len(standaloneDf)\n",
    "\n",
    "# Filter marvel\n",
    "standaloneDf = standaloneDf[standaloneDf['production_companies'].str.contains('Marvel') == False]\n",
    "f4 = len(standaloneDf)\n",
    "\n",
    "# Filter Star Wars\n",
    "standaloneDf = standaloneDf[standaloneDf['production_companies'].str.contains('Lucasfilm') == False]\n",
    "f5 = len(standaloneDf)\n",
    "\n",
    "standaloneDf.sort_values(by='revenue', ascending=False, inplace=True)\n",
    "print([f1,f2,f3,f4,f5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonIPTotalSums, nonIPAnnotations, nonIPAnnotationsFlat, nonIPIdNameMap = preprocessData(standaloneDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formatter function\n",
    "fig, axs = plt.subplots(2,1, figsize=(8,8))\n",
    "\n",
    "for idx, targetCol in enumerate(['revenue_sum','contribution_sum']):\n",
    "    ax = axs[idx]\n",
    "\n",
    "    ax.scatter(nonIPTotalSums['size'], nonIPTotalSums[targetCol], c = loadPalette()['blue_grey_dark'])\n",
    "\n",
    "    # Define line points\n",
    "    x_vals = np.array(ax.get_xlim())\n",
    "    y_vals = x_vals  # Slope of one\n",
    "\n",
    "    # Plot line\n",
    "\n",
    "    # Apply formatter to x and y axes\n",
    "    formatter = FuncFormatter(billions)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.set_xlabel('Number of Credits (non-animated)')\n",
    "\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Cumulative Revenue')\n",
    "    else:\n",
    "        ax.set_ylabel('Adjusted Cumulative Revenue')\n",
    "\n",
    "    xLim = 0\n",
    "    for annotation in nonIPAnnotations[idx][:20]:\n",
    "        try:\n",
    "            imgPath = f'../data/headshots/{annotation}/00_faceExtracted.png'\n",
    "            annotationData = nonIPTotalSums[nonIPTotalSums.index == annotation]\n",
    "            \n",
    "            if annotationData['size'].iloc[0] > xLim:\n",
    "                xLim = annotationData['size'].iloc[0]\n",
    "\n",
    "            x, y = annotationData['size'].iloc[0], annotationData[targetCol].iloc[0]\n",
    "            img = Image.open(imgPath)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "            img = img.resize((45, 45), Image.LANCZOS)  # Resize image with high-quality interpolation\n",
    "\n",
    "            imagebox = OffsetImage(img, zoom=0.5)  # Adjust zoom to fit the resized image\n",
    "            ab = AnnotationBbox(imagebox, (x, y), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    ax.set_xlim(0, xLim)\n",
    "\n",
    "fig.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.05, hspace=0.2, wspace=0.15)\n",
    "\n",
    "\n",
    "# Save image\n",
    "imageFilePath = os.path.join(saveImagePath, 'outlierScatterNonFranchise.png')\n",
    "plt.savefig(imageFilePath, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare awards across the two groups of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/actingAwards.html', 'r', encoding='utf-8') as file:\n",
    "    htmlContent = file.read()\n",
    "\n",
    "# Step 3: Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(htmlContent, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = soup.find_all(class_='result-subgroup')\n",
    "allTextBlob = \"\"\n",
    "for subgroup in subgroups:\n",
    "    internals = subgroup.find_all('div')\n",
    "    links = []\n",
    "    \n",
    "    for div in internals:        \n",
    "        nominationLink = div.find(class_='nominations-link')\n",
    "        if nominationLink:\n",
    "            linkText = nominationLink.get_text(strip=True)\n",
    "            if linkText not in links:\n",
    "                allTextBlob += linkText\n",
    "                links.append(linkText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPAwards = {}\n",
    "nonIPAwards = {}\n",
    "for annotation in annotations[1]:\n",
    "    name = idNameMap[annotation]\n",
    "\n",
    "    IPAwards[annotation] = allTextBlob.count(name)\n",
    "\n",
    "for annotation in nonIPAnnotations[1]:\n",
    "    name = nonIPIdNameMap[annotation]\n",
    "\n",
    "    nonIPAwards[annotation] = allTextBlob.count(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipDf = pd.DataFrame.from_dict({'count':IPAwards})\n",
    "ipDf['group'] = 'IP'\n",
    "nonIpDf = pd.DataFrame.from_dict({'count':nonIPAwards})\n",
    "nonIpDf['group'] = 'Non-IP'\n",
    "\n",
    "tDf = pd.concat([ipDf, nonIpDf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "group_a = tDf[tDf['group'] == 'IP']['count']\n",
    "group_b = tDf[tDf['group'] == 'Non-IP']['count']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = stats.ttest_ind(group_a, group_b)\n",
    "\n",
    "# Create boxplot\n",
    "ax.boxplot([group_a, group_b], labels=['IP','Non-IP'])\n",
    "ax.set_title(f'{column}')\n",
    "ax.set_xlabel('Group')\n",
    "ax.set_ylabel('Number of Oscar Nominations')\n",
    "\n",
    "# Overlay t-test results\n",
    "ax.text(1.5, max(group_a.max(), group_b.max()), f't-stat: {t_stat:.2f}\\np-value: {p_value:.3f}', \n",
    "    horizontalalignment='center', verticalalignment='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who is current biggest movie star in the world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNColumns(row, n):\n",
    "        return row.nlargest(n).index.tolist()\n",
    "\n",
    "def inTopN(df, n):\n",
    "        data = df.to_numpy()\n",
    "\n",
    "        topIdxs = np.argsort(data, axis=1)[:, -n:]\n",
    "\n",
    "        topCols = np.zeros(df.shape[1], dtype=bool)\n",
    "        for rowIdxs in topIdxs:\n",
    "                topCols[rowIdxs] = True\n",
    "\n",
    "        return df.columns[topCols]\n",
    "\n",
    "def prepDfForHorseRace(\n",
    "        df: pd.DataFrame = pd.DataFrame(),\n",
    "        yearRoll: int = 10,\n",
    "        targetCol: str = 'contribution',\n",
    "        department: str = 'Acting',\n",
    "        topN: int = 10,\n",
    "        cutoffDate: int = 1940\n",
    "):\n",
    "        timeDf = df.copy(deep=True)\n",
    "\n",
    "        print('PREPPING TIMEDF')\n",
    "        timeDf['year'] = pd.to_datetime(timeDf['release_date']).dt.year\n",
    "        timeDf = timeDf[timeDf['imdb_id'].isin(creditsDf['imdbId'].unique())]\n",
    "        timeDf.drop_duplicates(subset=['imdb_id'], inplace=True, keep='last')\n",
    "        timeDf['release_date'] = pd.to_datetime(timeDf['release_date'])\n",
    "        timeDf = timeDf[timeDf['release_date'] > pd.to_datetime(str(cutoffDate), format='%Y')]\n",
    "        timeDf = timeDf[timeDf['revenue'] > 0]\n",
    "        timeDf = timeDf[timeDf['budget'] > 0]\n",
    "        timeDf = timeDf[['imdb_id','release_date','revenue','budget']]\n",
    "        timeDf.set_index('imdb_id', inplace=True, drop=True)\n",
    "        tmdbDict = timeDf.to_dict('index')\n",
    "\n",
    "        print('MERGING IN CREDITS')\n",
    "        creditsDf['tmdbInfo'] = creditsDf['imdbId'].map(tmdbDict)\n",
    "        expDf = pd.json_normalize(creditsDf['tmdbInfo'])\n",
    "        resDf = creditsDf.drop(columns=['tmdbInfo']).join(expDf)\n",
    "        resDf = resDf[resDf['known_for_department'] == department]\n",
    "\n",
    "        print('CALCULATING COLS')\n",
    "        # Define good target cols\n",
    "        resDf['contribution'] = resDf['revenue'] / (resDf['cast_id'] + 1) # indexing starts at 0\n",
    "        resDf['RBR'] = resDf['revenue'] / resDf['budget'] # indexing starts at 0\n",
    "\n",
    "        resDf['starPower'] = resDf['RBR'] * resDf['contribution']\n",
    "\n",
    "        resDf.dropna(subset='release_date', inplace=True)\n",
    "        resDf['year'] = pd.to_datetime(resDf['release_date']).dt.year\n",
    "\n",
    "        print('GROUPING COLS')\n",
    "        gDf = pd.DataFrame(resDf.groupby(['year','id'])[targetCol].sum())\n",
    "        gDf.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        print('PIVOT!')\n",
    "        pivDf = gDf.pivot(index='year', columns='id', values=targetCol)\n",
    "\n",
    "        pivDf.fillna(0, inplace=True)\n",
    "        pivDf.index = pd.to_datetime(pivDf.index.astype(str), format='%Y')\n",
    "\n",
    "        # Fill in missing years with 0\n",
    "        resampledDf = pivDf.resample('Y').sum()\n",
    "        resampledDf = resampledDf.fillna(0)\n",
    "\n",
    "        # Resample to monthly frequency and apply polynomial interpolation\n",
    "        resampledDf = resampledDf.resample('M').interpolate(method='polynomial', order=2)\n",
    "        resampledDf[resampledDf < 0] = 0\n",
    "\n",
    "        pivRollDf = resampledDf.ewm(span=(yearRoll*12), adjust=False).mean()\n",
    "        pivRollDf.dropna(how='all', inplace=True)\n",
    "        \n",
    "        print(f\"NUMBER OF ROWS: {len(pivRollDf)}\")\n",
    "\n",
    "        # filtering out 1) future years and 2) People who have never been in the top 10 of any given year\n",
    "        pivRollDf = pivRollDf.iloc[:-1]\n",
    "        keepDict = inTopN(pivRollDf, topN)\n",
    "        resampledRollDfFiltered = pivRollDf[list(keepDict)]\n",
    "\n",
    "        return resampledRollDfFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {\n",
    "    \"1910's\":[pd.to_datetime('1910', format='%Y'), pd.to_datetime('1919', format='%Y')],\n",
    "    \"1920's\":[pd.to_datetime('1919', format='%Y'), pd.to_datetime('1929', format='%Y')],\n",
    "    \"1930's\":[pd.to_datetime('1929', format='%Y'), pd.to_datetime('1939', format='%Y')],\n",
    "    \"1940's\":[pd.to_datetime('1939', format='%Y'), pd.to_datetime('1949', format='%Y')],\n",
    "    \"1950's\":[pd.to_datetime('1949', format='%Y'), pd.to_datetime('1959', format='%Y')],\n",
    "    \"1960's\":[pd.to_datetime('1959', format='%Y'), pd.to_datetime('1969', format='%Y')],\n",
    "    \"1970's\":[pd.to_datetime('1969', format='%Y'), pd.to_datetime('1979', format='%Y')],\n",
    "    \"1980's\":[pd.to_datetime('1979', format='%Y'), pd.to_datetime('1989', format='%Y')],\n",
    "    \"1990's\":[pd.to_datetime('1989', format='%Y'), pd.to_datetime('1999', format='%Y')],\n",
    "    \"2000's\":[pd.to_datetime('1999', format='%Y'), pd.to_datetime('2009', format='%Y')],\n",
    "    \"2010's\":[pd.to_datetime('2009', format='%Y'), pd.to_datetime('2019', format='%Y')],\n",
    "    \"2020's\":[pd.to_datetime('2019', format='%Y'), pd.to_datetime('2029', format='%Y')]\n",
    "}\n",
    "\n",
    "def createHorseRace(\n",
    "        df: pd.DataFrame = pd.DataFrame,\n",
    "        figSize: tuple = (12,6),\n",
    "        annotations: dict = {},\n",
    "        windowSize: int = 72,\n",
    "        fps: int = 17,\n",
    "        dpi: int = 300, \n",
    "        xLabel: str = \"Date\",\n",
    "        yLabel: str = \"Box Office Power\",\n",
    "        filename: str = '',\n",
    "        saveImagePath: str = '',\n",
    "        yearRoll: int = 10\n",
    "    ):\n",
    "    # Assertions\n",
    "    assert filename != '', AssertionError('ERROR: SPECIFY A FILE NAME!')\n",
    "    assert saveImagePath != '', AssertionError('ERROR: SPECIFY YOUR GLOBAL IMAGE PATH!')\n",
    "    assert all([isinstance(c, int) for c in df.columns]), AssertionError('ERROR: COLUMNS OF DF ARE NOT OF CORRECT TYPE!')\n",
    "    assert isinstance(df.index, pd.DatetimeIndex), AssertionError('ERROR: INDEX OF DF IS NOT A DATETIME INDEX!')\n",
    "    if annotations != {}:\n",
    "        assert all(isinstance(v, list) and all(isinstance(date, pd.Timestamp) for date in v) for v in annotations.values()), AssertionError('ERROR: ANNOTATIONS VALUES ARE NOT LISTS OF pd.Timestamp!')\n",
    "\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    fontProp = FontProperties(fname='../assets/fonts/Lora/Lora-VariableFont_wght.ttf')\n",
    "\n",
    "    # We'll make sure that we have everyone's faces\n",
    "\n",
    "    for personId in tqdm(df.columns):\n",
    "        try:\n",
    "            headshotPath = f'../data/headshots({personId})'\n",
    "            if os.path.exists(headshotPath):\n",
    "                if '00_faceExtracted.png' in os.listdir(os.path.exists):\n",
    "                    continue\n",
    "\n",
    "            getHeadshot(personId, headers=headers)\n",
    "\n",
    "            filePath = f'../data/headshots/{personId}/{personId}_0.jpg'\n",
    "            \n",
    "            if os.path.exists(filePath):\n",
    "                extractFaces(filePath, makePretty=True)\n",
    "        except Exception as e:\n",
    "            exceptionOutput(e)\n",
    "            pass\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figSize)\n",
    "\n",
    "    def update(i):\n",
    "        ax.clear()\n",
    "        index = list(df.index)\n",
    "\n",
    "        # Set window boundaries\n",
    "        curMinRef = max(0, int(i-(windowSize*.9)))\n",
    "        curMaxRef = min(i+1, len(df)-1)\n",
    "\n",
    "        # Use boundaries to define plotted df\n",
    "        plotDf = df.iloc[curMinRef:curMaxRef]\n",
    "        ax.plot(plotDf, zorder=2)\n",
    "        \n",
    "        lastDate = plotDf.index.max()\n",
    "        lastRow = plotDf.iloc[-1]\n",
    "        \n",
    "        # Draw faces :) \n",
    "        visibleCols = topNColumns(lastRow, 10)\n",
    "        allYs = []\n",
    "        for personId in reversed(visibleCols):\n",
    "            try:\n",
    "                imgPath = f'../data/headshots/{personId}/00_faceExtracted.png'\n",
    "\n",
    "                img = Image.open(imgPath)\n",
    "                img = img.resize((80, 80), Image.LANCZOS)  # Resize image with high-quality interpolation\n",
    "\n",
    "                imagebox = OffsetImage(img, zoom=0.5)  # Adjust zoom to fit the resized image\n",
    "                x = index[i]\n",
    "                y = lastRow[personId]\n",
    "                allYs.append(y)\n",
    "                ab = AnnotationBbox(imagebox, (x, y), frameon=False)\n",
    "                ax.add_artist(ab)\n",
    "            except Exception as e:\n",
    "                # print([personId, idNameMap[personId]])\n",
    "                # print(exceptionOutput(e))\n",
    "                pass\n",
    "\n",
    "        if annotations != {}:\n",
    "            try:\n",
    "                annotation = [k for k,v in annotations.items() if ((lastDate > v[0]) and (lastDate <= v[1]))][0]\n",
    "                ax.text(0.5, 0.5, annotation, transform=ax.transAxes, fontsize=170, verticalalignment='center', horizontalalignment='center', alpha=0.25, color = loadPalette()['canvas_dark'], fontproperties=fontProp, zorder=1)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        ax.set_title(f'{yearRoll} Year Weighted Rolling Average (EWM)', fontsize=20)\n",
    "        ax.set_xlabel(xLabel, fontsize=14)\n",
    "        ax.set_ylabel(yLabel, fontsize=14)\n",
    "        ax.set_xlim(index[curMinRef], index[min(curMaxRef + 20, len(index)-1)])\n",
    "        ax.set_ylim(np.min(allYs)*.85, np.max(plotDf.values)*1.15)\n",
    "    \n",
    "    # Number of frames to hold the last frame (10 seconds at 24 fps)\n",
    "    hold_frames = 10 * fps\n",
    "\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(fig, update, frames=list(range(len(df))) + [len(df)-1]*hold_frames)\n",
    "\n",
    "\n",
    "    plt.tight_layout(pad=2.0, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "    # Save the animation to an mp4 file\n",
    "    ani.save(os.path.join(saveImagePath, f'{filename}.mp4'), writer='ffmpeg', fps=fps, dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Horserace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmation = input(\"Are you sure you want to proceed (This takes a longggg time)? (yes/no): \")\n",
    "\n",
    "# if confirmation.lower() == 'yes':\n",
    "allActingDf = prepDfForHorseRace(df = tmdbDfRaw)\n",
    "print(f\"WE'RE KEEPING {len(allActingDf.columns)} COLS\")\n",
    "\n",
    "createHorseRace(\n",
    "    df = allActingDf,\n",
    "    annotations = annotations,\n",
    "    filename = 'actorHorseRaceBoxOfficePowerRaw',\n",
    "    saveImagePath=saveImagePath,\n",
    "    fps=24,\n",
    "    dpi=300\n",
    ")\n",
    "# else:\n",
    "print(f\"PHEW! ON TO THE NEXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmation = input(\"Are you sure you want to proceed (This takes a longggg time)? (yes/no): \")\n",
    "\n",
    "# if confirmation.lower() == 'yes':\n",
    "nonIPDf = prepDfForHorseRace(df = standaloneDf, topN=5)\n",
    "print(f\"WE'RE KEEPING {len(nonIPDf.columns)} COLS\")\n",
    "\n",
    "\n",
    "with open('../assets/nonIPIds.json', 'w') as f:\n",
    "    json.dump(list(nonIPDf.columns), f)\n",
    "\n",
    "createHorseRace(\n",
    "    df = nonIPDf,\n",
    "    annotations = annotations,\n",
    "    filename = 'actorHorseRaceBoxOfficePowerNonIP',\n",
    "    saveImagePath=saveImagePath,\n",
    "    fps=24\n",
    ")\n",
    "# else:\n",
    "print(f\"PHEW! ON TO THE NEXT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use RBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation = input(\"Are you sure you want to proceed (This takes a longggg time)? (yes/no): \")\n",
    "\n",
    "if confirmation.lower() == 'yes':\n",
    "    # Eliminate micro budget movies\n",
    "    tmdbDfFiltered = tmdbDfRaw[tmdbDfRaw['budget'] > 5_000_000]\n",
    "    tmdbDfFiltered = tmdbDfFiltered[tmdbDfFiltered['revenue'] > 5_000_000]\n",
    "\n",
    "\n",
    "    nonIPDf = prepDfForHorseRace(df = tmdbDfFiltered, targetCol = 'starPower')\n",
    "    print(f\"WE'RE KEEPING {len(nonIPDf.columns)} COLS\")\n",
    "\n",
    "    createHorseRace(\n",
    "        df = nonIPDf,\n",
    "        annotations = annotations,\n",
    "        filename = 'actorHorseRaceStarPower',\n",
    "        saveImagePath=saveImagePath,\n",
    "        fps=32,\n",
    "        yLabel = 'Star Power'\n",
    "    )\n",
    "else:\n",
    "    print(f\"PHEW! ON TO THE NEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
