{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../library/')\n",
    "from midStats import cosSimWords\n",
    "from core import exceptionOutput\n",
    "from datetime import datetime\n",
    "import arrow\n",
    "import user_agent\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from tabulate import tabulate\n",
    "import ast\n",
    "import string\n",
    "\n",
    "r8 = redis.Redis(\n",
    "    host='localhost',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    db = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Redis Data from DB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = r8.keys()\n",
    "vals = r8.mget(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = [ast.literal_eval(v) for v in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in tmdb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdbDf = pd.read_csv('../data/tmdbDetails.csv')\n",
    "\n",
    "titleDict = tmdbDf.set_index('imdb_id')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Creits From Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r6 = redis.Redis(\n",
    "    host='127.0.0.1',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    db=6\n",
    ")\n",
    "\n",
    "keys = r6.keys('*')\n",
    "values = r6.mget(keys)\n",
    "\n",
    "creditsDict = []\n",
    "\n",
    "for i,v in enumerate(tqdm(values)):\n",
    "    vJ = json.loads(v)\n",
    "    imdbId = {'imdbId':keys[i]}\n",
    "    cast = [{**c, **imdbId} for c in vJ['cast']]\n",
    "    creditsDict += cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbCredits = {}\n",
    "\n",
    "for c in tqdm(creditsDict):\n",
    "    if c['imdbId'] not in imdbCredits.keys():\n",
    "        imdbCredits[c['imdbId']] = {\n",
    "            'title': titleDict[c['imdbId']].lower().translate(str.maketrans('','',string.punctuation)),\n",
    "            'people': []\n",
    "        }\n",
    "\n",
    "    imdbCredits[c['imdbId']]['people'].append(c['name'])\n",
    "\n",
    "assert len(imdbCredits.keys()) == len(set([c['imdbId'] for c in creditsDict])), AssertionError(\"MISSING KEYS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort for faster search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedCredits = dict(sorted(imdbCredits.items(), key=lambda item: item[1]['title']))\n",
    "\n",
    "for k, v in tqdm(sortedCredits.items()):\n",
    "    sortedCredits[k]['words'] = set([w.lower() for w in v['title'].replace('-',' ').split(' ')])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine sim to identify commonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franchiseTab = []\n",
    "allFranchiseIds = {}\n",
    "\n",
    "for franchiseData in tqdm(j):\n",
    "    for franchiseName, franchiseMovies in franchiseData.items():\n",
    "        franchiseTab.append([franchiseName, len(franchiseMovies)])\n",
    "\n",
    "        movieIds = {}\n",
    "\n",
    "        for k, innerDict in franchiseMovies.items():\n",
    "            try:\n",
    "                if isinstance(innerDict['title'], list):\n",
    "                    innerDict['title'] = innerDict['title'][0]\n",
    "\n",
    "                title = innerDict['title'].replace('-',' ').lower().translate(str.maketrans('', '', string.punctuation))\n",
    "                people = [p.lower().translate(str.maketrans('', '', string.punctuation)) for p in innerDict['people']][:5]\n",
    "                titleWords = set([w.lower() for w in title.split(' ')])\n",
    "\n",
    "                # Filter out credits with no people\n",
    "                def filterCredits(sortedCredits: dict, simThresh: int = 1):\n",
    "                    filteredCredits = {k: v for k, v in sortedCredits.items() if \\\n",
    "                        len(v['words'].intersection(titleWords)) >= min(len(v['words']), len(titleWords))\n",
    "                    }\n",
    "\n",
    "                    return filteredCredits\n",
    "                \n",
    "                filteredCredits = filterCredits(sortedCredits)\n",
    "\n",
    "                if len(filteredCredits) == 0:\n",
    "                    movieIds[k] = None\n",
    "                    continue\n",
    "\n",
    "                # Sort by length of intersection\n",
    "                sortedFilteredCredits = dict(sorted(filteredCredits.items(), key=lambda item: len(set(people).intersection(set([e.lower() for e in item[1]['people'][:5]])))/len(item[1]['people']), reverse=True))          \n",
    "\n",
    "                maxSims = {}\n",
    "                for imdbId, c in sortedFilteredCredits.items():\n",
    "                    try:\n",
    "                        titleSim = cosSimWords(title.lower(), c['title'].lower(), analyzer='char', ngram_range=(2,3), justBool=False)                   \n",
    "                        maxSims[imdbId] = titleSim\n",
    "                        if titleSim >= .99:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        exceptionOutput(e)\n",
    "                        pass\n",
    "                \n",
    "                if len(maxSims) > 0 and max(maxSims.values()) > .75:\n",
    "                    movieIds[k] = max(maxSims, key=maxSims.get)\n",
    "                else:\n",
    "                    movieIds[k] = None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(exceptionOutput(e))\n",
    "                pass    \n",
    "            \n",
    "            allFranchiseIds[franchiseName] = movieIds\n",
    "\n",
    "print('')\n",
    "print(tabulate(franchiseTab, headers=['Franchise',\"Number of Movies\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/franchiseMappings.json', 'w') as f:\n",
    "#     json.dump(allFranchiseIds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do one more pass for null imdbids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all null\n",
    "\n",
    "foundIds = []\n",
    "missingIds = []\n",
    "for franchise, movies in allFranchiseIds.items():\n",
    "    for movieId, imdbId in movies.items():\n",
    "        if imdbId != None:\n",
    "            foundIds.append(imdbId)\n",
    "        else:\n",
    "            missingIds.append(movieId)\n",
    "\n",
    "print(f\"NUMBER OF FOUND IDS: {len(foundIds)}\")\n",
    "print(f\"NUMBER OF MISSING IDS: {len(missingIds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove found ids from candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbVectors = []\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "for imdbId, data in imdbCredits.items():\n",
    "    if imdbId in foundIds:\n",
    "        continue\n",
    "    \n",
    "    titleStripped = data['title'].lower().translate(translator)\n",
    "    peopleStripped = ' '.join(data['people'][:5]).lower().translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    fullStr = titleStripped + ' ' + peopleStripped\n",
    "\n",
    "    imdbVectors.append((imdbId, fullStr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate Missing Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "jFiltered = []\n",
    "\n",
    "for f in j:\n",
    "    fD = {}\n",
    "    for t, ms in f.items():\n",
    "\n",
    "        fD[t] = {}\n",
    "        for mt, md in ms.items():\n",
    "            if mt in missingIds:\n",
    "                fD[t][mt]=md\n",
    "\n",
    "\n",
    "    if len(fD[t]) > 0:\n",
    "        jFiltered.append(fD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franchiseTab = []\n",
    "newFranchiseIds = {}\n",
    "\n",
    "for franchiseData in tqdm(jFiltered):\n",
    "    for franchiseName, franchiseMovies in franchiseData.items():\n",
    "        franchiseTab.append([franchiseName, len(franchiseMovies)])\n",
    "\n",
    "        movieIds = {}\n",
    "\n",
    "        for k, innerDict in franchiseMovies.items():\n",
    "            try:\n",
    "                if isinstance(innerDict['title'], list):\n",
    "                    innerDict['title'] = innerDict['title'][0]\n",
    "\n",
    "                title = innerDict['title'].replace('-',' ').lower().translate(str.maketrans('', '', string.punctuation))\n",
    "                people = [p.lower().translate(str.maketrans('', '', string.punctuation)) for p in innerDict['people']][:5]\n",
    "                titleWords = set([w.lower() for w in title.split(' ')])\n",
    "\n",
    "                # Filter out credits with no people\n",
    "                def filterCredits(sortedCredits: dict, simThresh: int = 1):\n",
    "                    filteredCredits = {k: v for k, v in sortedCredits.items() if \\\n",
    "                        len(v['words'].intersection(titleWords)) >= simThresh\n",
    "                    }\n",
    "\n",
    "                    return filteredCredits\n",
    "                \n",
    "                filteredCredits = filterCredits(sortedCredits, 2)\n",
    "\n",
    "                if len(filteredCredits) == 0:\n",
    "                    filteredCredits = filterCredits(sortedCredits, 1)\n",
    "\n",
    "                if len(filteredCredits) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Sort by length of intersection\n",
    "                sortedFilteredCredits = dict(sorted(filteredCredits.items(), key=lambda item: len(set(people).intersection(set([e.lower() for e in item[1]['people'][:5]])))/len(item[1]['people']), reverse=True))          \n",
    "\n",
    "                maxSims = {}\n",
    "                for imdbId, c in sortedFilteredCredits.items():\n",
    "                    try:\n",
    "                        titleSim = cosSimWords(title.lower().translate(translator), c['title'].lower().translate(translator), analyzer='char', ngram_range=(2,6), justBool=False)                   \n",
    "\n",
    "                        maxSims[imdbId] = titleSim\n",
    "                        if titleSim >= .99:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        exceptionOutput(e)\n",
    "                        pass\n",
    "                \n",
    "                if len(maxSims) > 0:\n",
    "                    movieIds[k] = max(maxSims, key=maxSims.get)\n",
    "                else:\n",
    "                    movieIds[k] = None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(exceptionOutput(e))\n",
    "                pass    \n",
    "            \n",
    "            newFranchiseIds[franchiseName] = movieIds\n",
    "\n",
    "print('')\n",
    "print(tabulate(franchiseTab, headers=['Franchise',\"Number of Movies\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_nested_dicts(dict1, dict2):\n",
    "    combined_dict = {}\n",
    "\n",
    "    # Get all unique keys from both dictionaries\n",
    "    all_keys = set(dict1.keys()).union(set(dict2.keys()))\n",
    "\n",
    "    for key in all_keys:\n",
    "        if key in dict1 and key in dict2:\n",
    "            # Combine values if key exists in both dictionaries\n",
    "            combined_dict[key] = {**dict1[key], **dict2[key]}\n",
    "        elif key in dict1:\n",
    "            # Add value from dict1 if key exists only in dict1\n",
    "            combined_dict[key] = dict1[key]\n",
    "        else:\n",
    "            # Add value from dict2 if key exists only in dict2\n",
    "            combined_dict[key] = dict2[key]\n",
    "\n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeFranchiseIds = combine_nested_dicts(allFranchiseIds, newFranchiseIds)\n",
    "\n",
    "with open('../data/franchiseMappings2.json', 'w') as f:\n",
    "    json.dump(completeFranchiseIds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Heuristic Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
