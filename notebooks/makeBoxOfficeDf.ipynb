{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../library')\n",
    "from core import extractBetween, extractElementsInOrder, exceptionOutput\n",
    "from datetime import datetime\n",
    "import arrow\n",
    "\n",
    "r = redis.Redis(\n",
    "    host='localhost',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True,\n",
    "    db = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Redis Data from DB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = r.keys()\n",
    "vals = r.mget(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form Basic Dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsJson = [json.loads(e) for e in vals]\n",
    "rawDf = pd.DataFrame.from_dict(valsJson)\n",
    "\n",
    "weekendDf = rawDf[rawDf['isWeekend'] == True]\n",
    "weekdayDf = rawDf[rawDf['isWeekend'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explodeAndStack(df, column):\n",
    "    # Create a list to hold the individual DataFrames\n",
    "    explodedDfs = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert the list of lists into a DataFrame\n",
    "        tempDf = pd.DataFrame(row[column])\n",
    "        # Append the DataFrame to the list with the original index as a key\n",
    "        explodedDfs.append((index, tempDf))\n",
    "\n",
    "    # Concatenate all the DataFrames in the list with keys to maintain the index\n",
    "    resultDf = pd.concat([df for _, df in explodedDfs], keys=[index for index, _ in explodedDfs])\n",
    "    \n",
    "    return resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids for mapping\n",
    "weekendIdxDict = weekendDf['imdbId'].to_dict()\n",
    "weekdayIdxDict = weekdayDf['imdbId'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIdx(df: pd.DataFrame, d: dict, columns: list):\n",
    "    dfOut = explodeAndStack(df, 'tableData').reset_index(drop=False)\n",
    "    dfOut['imdbId'] = dfOut['level_0'].map(d)\n",
    "    dfOut.drop(columns=['level_0','level_1', 9], inplace=True)\n",
    "\n",
    "    assert len(columns) == dfOut.shape[1], f\"Mismatch in column lengths and df shape: {len(columns)} != {len(dfOut.columns)}\"\n",
    "\n",
    "    dfOut.columns = columns\n",
    "    \n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekendCols = ['date','rank','weekend','pct','numberOfTheaters','theaterChange','averagePerTheater','toDate','weekendNumber', 'imdbId']\n",
    "weekdayCols = ['date', 'DOW', 'rank', 'daily', 'dayPct', 'weekPct', 'numberOfTheaters', 'averagePerTheater', 'toDate', 'dayNumber','imdbId']\n",
    "\n",
    "weekendDf = mapIdx(weekendDf, weekendIdxDict, weekendCols)\n",
    "weekdayDf = mapIdx(weekdayDf, weekdayIdxDict, weekdayCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dfs Compatible\n",
    "- Will need to convert weekend to daily...\n",
    "- To do this, we'll use toDate and weekend in order to impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/znvh8gg96055nsx1ptsrmmvc0000gn/T/ipykernel_44141/251818170.py:1: DtypeWarning: Columns (1,24,27,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tmdbDf = pd.read_csv('../data/tmdbDetails.csv')\n"
     ]
    }
   ],
   "source": [
    "tmdbDf = pd.read_csv('../data/tmdbDetails.csv')\n",
    "tmdbDf.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "releaseDates = tmdbDf.set_index('imdb_id')['release_date'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekendDf = weekendDf[weekendDf['date'] != None]\n",
    "weekendDf.dropna(subset='date', inplace=True)\n",
    "\n",
    "def extractDates(date: str, imdbId: str, releaseDates: dict):\n",
    "    try:\n",
    "        months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "        # determine if the weekend spans two months\n",
    "        # foundMonths = [m for m in months if m in date]\n",
    "        foundMonths = extractElementsInOrder(date, months)\n",
    "        multiMonth = True if len(foundMonths) > 1 else False\n",
    "\n",
    "        if releaseDates[imdbId] != releaseDates[imdbId]:\n",
    "            return None, None\n",
    "        \n",
    "        releaseDate = releaseDates[imdbId].split('-')[0]\n",
    "    \n",
    "\n",
    "        if not multiMonth:\n",
    "            startDateStr = f\"{foundMonths[0]}. {extractBetween(date, ' ','-')}, {releaseDate}\"\n",
    "            endDayNumber = re.search(r'\\d+', date.split('-')[1]).group()  # Extract the numerical part for days when there are holidays\n",
    "            endDateStr   = f\"{foundMonths[0]}. {endDayNumber}, {releaseDate}\"\n",
    "        else:\n",
    "            startMonth = foundMonths[0]\n",
    "            endMonth   = foundMonths[1]\n",
    "\n",
    "            startDay = extractBetween(date, f'{startMonth} ', '-')\n",
    "            endDay   = re.search(r'\\d+', date.split(f'{endMonth} ')[1]).group()\n",
    "            startDateStr = f\"{foundMonths[0]}. {startDay}, {releaseDate}\"\n",
    "            endDateStr   = f\"{foundMonths[1]}. {endDay}, {releaseDate}\"\n",
    "\n",
    "        try:\n",
    "            startDate = arrow.get(startDateStr, \"MMM. D, YYYY\")\n",
    "            endDate   = arrow.get(endDateStr, \"MMM. D, YYYY\")\n",
    "        except: # it's not happy with leap years... may need to investigate this further TODO\n",
    "            startDateStr = startDateStr.replace('Feb. 29', 'Feb. 28')\n",
    "            endDateStr   = endDateStr.replace('Feb. 29', 'Feb. 28')\n",
    "            startDate = arrow.get(startDateStr, \"MMM. D, YYYY\")\n",
    "            endDate   = arrow.get(endDateStr, \"MMM. D, YYYY\")\n",
    "\n",
    "\n",
    "        # rare condition where weekend is over the new year\n",
    "        # haven't actually encountered this, may be formatted weirdly\n",
    "        if endDate < startDate:\n",
    "            endDate = endDate.shift(years=1)\n",
    "\n",
    "        return [startDate, endDate]\n",
    "    except Exception as e:\n",
    "        print(exceptionOutput(e))\n",
    "\n",
    "\n",
    "startAndEndDates = weekendDf.apply(lambda row: extractDates(row['date'], row['imdbId'], releaseDates), axis=1)\n",
    "weekendDf[['startDate', 'endDate']] = startAndEndDates.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekendDf.drop_duplicates(subset=['imdbId', 'weekendNumber'], inplace=True)\n",
    "\n",
    "for col in ['weekend','averagePerTheater','numberOfTheaters','toDate', 'pct']:\n",
    "    weekendDf[col] = weekendDf[col].str.replace('$','', regex=False)\\\n",
    "                                    .str.replace(',','',regex=False)\\\n",
    "                                    .str.replace('%','',regex=False)\\\n",
    "                                    .str.replace('<','',regex=False)\\\n",
    "                                    .replace('-', np.nan)\\\n",
    "                                    .astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>weekend</th>\n",
       "      <th>pct</th>\n",
       "      <th>numberOfTheaters</th>\n",
       "      <th>theaterChange</th>\n",
       "      <th>averagePerTheater</th>\n",
       "      <th>toDate</th>\n",
       "      <th>weekendNumber</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19381</th>\n",
       "      <td>Feb 17-19</td>\n",
       "      <td>9</td>\n",
       "      <td>49945.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-</td>\n",
       "      <td>192.0</td>\n",
       "      <td>49945.0</td>\n",
       "      <td>1</td>\n",
       "      <td>tt25786030</td>\n",
       "      <td>2023-02-17T00:00:00+00:00</td>\n",
       "      <td>2023-02-19T00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19382</th>\n",
       "      <td>Feb 24-26</td>\n",
       "      <td>14</td>\n",
       "      <td>7257.0</td>\n",
       "      <td>-85.5</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-144</td>\n",
       "      <td>63.0</td>\n",
       "      <td>68296.0</td>\n",
       "      <td>2</td>\n",
       "      <td>tt25786030</td>\n",
       "      <td>2023-02-24T00:00:00+00:00</td>\n",
       "      <td>2023-02-26T00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19383</th>\n",
       "      <td>Mar 3-5</td>\n",
       "      <td>31</td>\n",
       "      <td>649.0</td>\n",
       "      <td>-91.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-107</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70751.0</td>\n",
       "      <td>3</td>\n",
       "      <td>tt25786030</td>\n",
       "      <td>2023-03-03T00:00:00+00:00</td>\n",
       "      <td>2023-03-05T00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19384</th>\n",
       "      <td>Mar 10-12</td>\n",
       "      <td>41</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-89.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70514.0</td>\n",
       "      <td>4</td>\n",
       "      <td>tt25786030</td>\n",
       "      <td>2023-03-10T00:00:00+00:00</td>\n",
       "      <td>2023-03-12T00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19385</th>\n",
       "      <td>Mar 24-26</td>\n",
       "      <td>34</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>114.0</td>\n",
       "      <td>70263.0</td>\n",
       "      <td>6</td>\n",
       "      <td>tt25786030</td>\n",
       "      <td>2023-03-24T00:00:00+00:00</td>\n",
       "      <td>2023-03-26T00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date rank  weekend   pct  numberOfTheaters theaterChange  \\\n",
       "19381  Feb 17-19    9  49945.0   NaN             259.0             -   \n",
       "19382  Feb 24-26   14   7257.0 -85.5             115.0          -144   \n",
       "19383    Mar 3-5   31    649.0 -91.1               8.0          -107   \n",
       "19384  Mar 10-12   41     70.0 -89.2               2.0            -6   \n",
       "19385  Mar 24-26   34    114.0   NaN               1.0             -   \n",
       "\n",
       "       averagePerTheater   toDate weekendNumber      imdbId  \\\n",
       "19381              192.0  49945.0             1  tt25786030   \n",
       "19382               63.0  68296.0             2  tt25786030   \n",
       "19383               81.0  70751.0             3  tt25786030   \n",
       "19384               35.0  70514.0             4  tt25786030   \n",
       "19385              114.0  70263.0             6  tt25786030   \n",
       "\n",
       "                       startDate                    endDate  \n",
       "19381  2023-02-17T00:00:00+00:00  2023-02-19T00:00:00+00:00  \n",
       "19382  2023-02-24T00:00:00+00:00  2023-02-26T00:00:00+00:00  \n",
       "19383  2023-03-03T00:00:00+00:00  2023-03-05T00:00:00+00:00  \n",
       "19384  2023-03-10T00:00:00+00:00  2023-03-12T00:00:00+00:00  \n",
       "19385  2023-03-24T00:00:00+00:00  2023-03-26T00:00:00+00:00  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekendDf[weekendDf['imdbId'] == 'tt25786030']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute weekend days and then interpolate weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeDates(group):\n",
    "    \"\"\"\n",
    "    This function takes place in two parts:\n",
    "    1. Impute data within an individual weekend\n",
    "    2. Interpolate data across weekends\n",
    "\n",
    "    By breaking this into two parts we take advantage of the limited granularity that we do actually have\n",
    "\n",
    "    Assumptions and known issues:\n",
    "    - Box office distribution is not linear across days within a weekend nor a weekday\n",
    "    - There may be gradual declines in theater counts\n",
    "    - This is a bit slow, should test with modin to see performance difference\n",
    "\n",
    "    Future solutions:\n",
    "    - Develop basic ml model, could probably be just simple linear regression, based on actual daily data to look at the degredation of box office across a weekend or week\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        _tempDf = []\n",
    "\n",
    "\n",
    "        # Part 1\n",
    "        for idx, row in group.iterrows():\n",
    "            dateRange = [dt for dt in arrow.Arrow.range('day', row['startDate'], row['endDate'])]\n",
    "            perDay = row['weekend']/len(dateRange)\n",
    "            \n",
    "            for date in dateRange:\n",
    "                _tempDf.append({\n",
    "                    'date': date,\n",
    "                    # 'DOW': later\n",
    "                    'rank': row['rank'],\n",
    "                    'daily': perDay,\n",
    "                    # 'dayPct': later\n",
    "                    'numberOfTheaters':row['numberOfTheaters'],\n",
    "                    'averagePerTheater':row['averagePerTheater'],\n",
    "                    # 'toDate': later\n",
    "                    # 'dayNumber': later\n",
    "                    'imdbId': row['imdbId']\n",
    "                })\n",
    "\n",
    "        imputedDf = pd.DataFrame.from_dict(_tempDf)\n",
    "\n",
    "        # Part 2\n",
    "        minDate = imputedDf['date'].min()\n",
    "        maxDate = imputedDf['date'].max()\n",
    "\n",
    "        idxDf = pd.DataFrame(index=[dt for dt in arrow.Arrow.range('day', minDate, maxDate)])\n",
    "        fullDateDf = idxDf.merge(imputedDf, left_index=True, right_on='date', how = 'left')\n",
    "        fullDateDf['DOW'] = fullDateDf['date'].apply(lambda x: x.format('dddd'))\n",
    "        fullDateDf.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        ffillCols = ['rank','numberOfTheaters','imdbId']\n",
    "        interpCols = ['daily']\n",
    "\n",
    "        for col in ffillCols:\n",
    "            fullDateDf[col] = fullDateDf[col].ffill()\n",
    "\n",
    "        for col in interpCols:\n",
    "            fullDateDf[col] = fullDateDf[col].interpolate(method='polynomial', order = 2)\n",
    "\n",
    "        fullDateDf['dayPct'] = fullDateDf['daily'].pct_change() * 100\n",
    "        fullDateDf['averagePerTheater'] = fullDateDf['daily'].astype(float) / fullDateDf['numberOfTheaters'].astype(float)\n",
    "        fullDateDf['toDate'] = fullDateDf['daily'].cumsum()\n",
    "        fullDateDf['dayNumber'] = list([i+1 for i in fullDateDf.index])\n",
    "\n",
    "        return fullDateDf\n",
    "                \n",
    "    except Exception as e:\n",
    "        # print(exceptionOutput(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zz/znvh8gg96055nsx1ptsrmmvc0000gn/T/ipykernel_44141/334439980.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  imputedDf = weekendDf.groupby('imdbId').apply(lambda group: imputeDates(group))\n"
     ]
    }
   ],
   "source": [
    "imputedDf = weekendDf.groupby('imdbId').apply(lambda group: imputeDates(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert weekday to match our pretty weekndDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>DOW</th>\n",
       "      <th>rank</th>\n",
       "      <th>daily</th>\n",
       "      <th>dayPct</th>\n",
       "      <th>weekPct</th>\n",
       "      <th>numberOfTheaters</th>\n",
       "      <th>averagePerTheater</th>\n",
       "      <th>toDate</th>\n",
       "      <th>dayNumber</th>\n",
       "      <th>imdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tt0245803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apr 16</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2</td>\n",
       "      <td>$1,443,477</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2,955</td>\n",
       "      <td>$488</td>\n",
       "      <td>$1,443,477</td>\n",
       "      <td>false</td>\n",
       "      <td>tt0245803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 17</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>$1,652,222</td>\n",
       "      <td>+14.5%</td>\n",
       "      <td>-</td>\n",
       "      <td>2,955</td>\n",
       "      <td>$559</td>\n",
       "      <td>$3,095,699</td>\n",
       "      <td>false</td>\n",
       "      <td>tt0245803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr 18</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "      <td>$3,265,329</td>\n",
       "      <td>+97.6%</td>\n",
       "      <td>-</td>\n",
       "      <td>2,955</td>\n",
       "      <td>$1,105</td>\n",
       "      <td>$6,361,028</td>\n",
       "      <td>false</td>\n",
       "      <td>tt0245803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 19</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>4</td>\n",
       "      <td>$3,123,644</td>\n",
       "      <td>-4.3%</td>\n",
       "      <td>-</td>\n",
       "      <td>2,955</td>\n",
       "      <td>$1,057</td>\n",
       "      <td>$9,484,672</td>\n",
       "      <td>false</td>\n",
       "      <td>tt0245803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date        DOW  rank       daily  dayPct weekPct numberOfTheaters  \\\n",
       "0    None       None  None        None    None    None             None   \n",
       "1  Apr 16  Wednesday     2  $1,443,477       -       -            2,955   \n",
       "2  Apr 17   Thursday     2  $1,652,222  +14.5%       -            2,955   \n",
       "3  Apr 18     Friday     4  $3,265,329  +97.6%       -            2,955   \n",
       "4  Apr 19   Saturday     4  $3,123,644   -4.3%       -            2,955   \n",
       "\n",
       "  averagePerTheater      toDate dayNumber     imdbId  \n",
       "0              None        None      None  tt0245803  \n",
       "1              $488  $1,443,477     false  tt0245803  \n",
       "2              $559  $3,095,699     false  tt0245803  \n",
       "3            $1,105  $6,361,028     false  tt0245803  \n",
       "4            $1,057  $9,484,672     false  tt0245803  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekdayDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdayDf.drop_duplicates(subset=['imdbId', 'date'], inplace=True)\n",
    "\n",
    "for col in ['daily','averagePerTheater','numberOfTheaters','toDate', 'dayPct','weekPct']:\n",
    "    weekdayDf[col] = weekdayDf[col].str.replace('$','', regex=False)\\\n",
    "                                    .str.replace(',','',regex=False)\\\n",
    "                                    .str.replace('%','',regex=False)\\\n",
    "                                    .str.replace('<','',regex=False)\\\n",
    "                                    .replace('-', np.nan)\\\n",
    "                                    .astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on line 16 || ParserMatchError || Failed to match 'MMM. D, YYYY' when parsing 'Sep. 119, 2001'.\n"
     ]
    }
   ],
   "source": [
    "def getArrowDate(row):\n",
    "    try:\n",
    "        releaseDate = releaseDates.get(row['imdbId'], np.nan)\n",
    "\n",
    "        if releaseDate != releaseDate:\n",
    "            return \n",
    "        \n",
    "        releaseDate = releaseDate.split('-')[0]\n",
    "        dayNumber   = re.search(r'\\d+', row['date'].split(' ')[1]).group()\n",
    "        dateStr = f\"{row['date'].split(' ')[0]}. {dayNumber}, {releaseDate}\"\n",
    "\n",
    "        try:\n",
    "            dateArr = arrow.get(dateStr, \"MMM. D, YYYY\")\n",
    "        except: # also not happy with leap years\n",
    "            dateStr = dateStr.replace('Feb. 29','Feb. 28')\n",
    "            dateArr = arrow.get(dateStr, \"MMM. D, YYYY\")\n",
    "            \n",
    "\n",
    "        return dateArr\n",
    "    except Exception as e:\n",
    "        exceptionOutput(e)\n",
    "\n",
    "weekdayDf = weekdayDf[weekdayDf['date'] != None]\n",
    "weekdayDf.dropna(subset='date', inplace=True)\n",
    "\n",
    "\n",
    "weekdayDf['date'] = weekdayDf.apply(lambda row: getArrowDate(row), axis=1)\n",
    "weekdayDf['_1'] = 1\n",
    "\n",
    "weekdayDf['dayNumber'] = weekdayDf.groupby('imdbId')['_1'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputedDf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "      <th>daily</th>\n",
       "      <th>numberOfTheaters</th>\n",
       "      <th>averagePerTheater</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>DOW</th>\n",
       "      <th>dayPct</th>\n",
       "      <th>toDate</th>\n",
       "      <th>dayNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1919-12-02T00:00:00+00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>tt0010680</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1919-12-03T00:00:00+00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>tt0010680</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1919-12-04T00:00:00+00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>tt0010680</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1919-12-05T00:00:00+00:00</td>\n",
       "      <td>102</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>tt0010680</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1921-11-21T00:00:00+00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>4818.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>481.88</td>\n",
       "      <td>tt0012349</td>\n",
       "      <td>Monday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4818.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       date rank   daily  numberOfTheaters  \\\n",
       "0    0.0  1919-12-02T00:00:00+00:00  102    40.0               1.0   \n",
       "1    1.0  1919-12-03T00:00:00+00:00  102    40.0               1.0   \n",
       "2    2.0  1919-12-04T00:00:00+00:00  102    40.0               1.0   \n",
       "3    3.0  1919-12-05T00:00:00+00:00  102    40.0               1.0   \n",
       "4    0.0  1921-11-21T00:00:00+00:00   43  4818.8              10.0   \n",
       "\n",
       "   averagePerTheater     imdbId        DOW  dayPct  toDate  dayNumber  \n",
       "0              40.00  tt0010680    Tuesday     NaN    40.0          1  \n",
       "1              40.00  tt0010680  Wednesday     0.0    80.0          2  \n",
       "2              40.00  tt0010680   Thursday     0.0   120.0          3  \n",
       "3              40.00  tt0010680     Friday     0.0   160.0          4  \n",
       "4             481.88  tt0012349     Monday     NaN  4818.8          1  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputedDf.drop(columns=['index'], inplace=True)\n",
    "weekdayDf.drop(columns=['weekPct', '_1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted(imputedDf.columns) == sorted(weekdayDf.columns), \"ASSERTION ERROR: Two Dfs do not contain the same columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf = pd.concat([imputedDf, weekdayDf], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf.to_csv('../data/allBoxOffice.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
